# Prediction_On_HousePrice

I recently participated in a Kaggle machine learning competition with the goal of building a model that accurately predicts house prices. The competition provided us with a dataset containing a variety of features such as the number of bedrooms, bathrooms, and square footage of each house.

To begin, I cleaned the dataset and performed some feature engineering to extract meaningful information from the available features. I also conducted an exploratory data analysis to identify any patterns or trends in the data and gain a better understanding of the relationships between different variables.

Next, I started building machine learning models using various algorithms such as linear regression, random forest, xg boost, lasso, ridge and gradient boosting. I also did some hyperparameter tuning to optimize the performance of each model and achieve better results. Additionally, I experimented with ensemble models, such as stacking and blending, to combine the strengths of multiple models and improve overall performance.

Throughout the competition, I used a variety of techniques to improve my model's performance, including feature selection, regularization, and cross-validation. I also carefully evaluated each model's performance using metrics such as mean squared error and root mean squared error.

After several iterations and rounds of model training and evaluation, I achieved a final rank of 730 in the competition. Although there is always room for improvement, I am proud of the progress I made and the skills I developed through this experience. Overall, the competition was a great opportunity to apply my machine learning knowledge to a real-world problem and learn from the insights and strategies of other data scientists.
